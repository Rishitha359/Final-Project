{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREP LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Employee data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Null Values and DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Emp_id           200 non-null    int64 \n",
      " 1   name             200 non-null    object\n",
      " 2   email            200 non-null    object\n",
      " 3   password         200 non-null    object\n",
      " 4   Gender           200 non-null    object\n",
      " 5   Role             200 non-null    object\n",
      " 6   Region           200 non-null    object\n",
      " 7   Department       200 non-null    object\n",
      " 8   Designation      200 non-null    object\n",
      " 9   Date_of_Birth    200 non-null    object\n",
      " 10  Date_of_Joining  200 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 17.3+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Emp_id           200 non-null    int64 \n",
      " 1   name             200 non-null    object\n",
      " 2   email            200 non-null    object\n",
      " 3   password         200 non-null    object\n",
      " 4   Gender           200 non-null    object\n",
      " 5   Role             200 non-null    object\n",
      " 6   Region           200 non-null    object\n",
      " 7   Department       200 non-null    object\n",
      " 8   Designation      200 non-null    object\n",
      " 9   Date_of_Birth    200 non-null    object\n",
      " 10  Date_of_Joining  200 non-null    object\n",
      "dtypes: int64(1), object(10)\n",
      "memory usage: 17.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "employees_df = pd.read_csv(r'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Raw\\raw_employees.csv')\n",
    "\n",
    "employees_df.info()\n",
    "\n",
    "# Converting date column datatype to DateTime format\n",
    "employees_df['Date_of_Birth'] = pd.to_datetime(employees_df['Date_of_Birth'], errors='coerce').dt.date\n",
    "employees_df['Date_of_Joining'] = pd.to_datetime(employees_df['Date_of_Joining'], errors='coerce').dt.date\n",
    "\n",
    "employees_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = employees_df.duplicated()\n",
    "count_Of_Duplicates = 0\n",
    "for i in duplicates:\n",
    "    if i == 'True':\n",
    "        count_Of_Duplicates += 1\n",
    "print(count_Of_Duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating email format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_email(email):\n",
    "    pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "    return re.match(pattern, email) is not None\n",
    "\n",
    "employees_df['valid_email'] = employees_df['email'].apply(is_valid_email)\n",
    "employees_df = employees_df[employees_df['valid_email']].drop(columns='valid_email')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if emails are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emails are unique.\n"
     ]
    }
   ],
   "source": [
    "if employees_df['email'].is_unique:\n",
    "    print(\"All emails are unique.\")\n",
    "else:\n",
    "    print(\"There are duplicate emails!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving csv file into Prep Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employees data cleaned and saved to 'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Prep\\prep_employees.csv'.\n"
     ]
    }
   ],
   "source": [
    "output_file = r'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Prep\\prep_employees.csv'\n",
    "\n",
    "employees_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Employees data cleaned and saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Null Values and DataTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   training_id    30 non-null     int64 \n",
      " 1   training_name  30 non-null     object\n",
      " 2   start_date     30 non-null     object\n",
      " 3   end_date       30 non-null     object\n",
      " 4   Trainer_id     30 non-null     int64 \n",
      " 5   domain         30 non-null     object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30 entries, 0 to 29\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   training_id    30 non-null     int64 \n",
      " 1   training_name  30 non-null     object\n",
      " 2   start_date     30 non-null     object\n",
      " 3   end_date       30 non-null     object\n",
      " 4   Trainer_id     30 non-null     int64 \n",
      " 5   domain         30 non-null     object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "training_df = pd.read_csv(r'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Raw\\raw_trainings.csv')\n",
    "\n",
    "training_df.info()\n",
    "\n",
    "# Converting date column datatype to DateTime format\n",
    "training_df['start_date'] = pd.to_datetime(training_df['start_date'], errors='coerce').dt.date\n",
    "training_df['end_date'] = pd.to_datetime(training_df['end_date'], errors='coerce').dt.date\n",
    "\n",
    "training_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = training_df.duplicated()\n",
    "count_Of_Duplicates = 0\n",
    "for i in duplicates:\n",
    "    if i == 'True':\n",
    "        count_Of_Duplicates += 1\n",
    "print(count_Of_Duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if trainings are unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All trainings are unique.\n"
     ]
    }
   ],
   "source": [
    "if training_df['training_name'].is_unique:\n",
    "    print(\"All trainings are unique.\")\n",
    "else:\n",
    "    print(\"There are duplicate trainings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving csv file into Prep Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data cleaned and saved to 'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Prep\\prep_trainings.csv'.\n"
     ]
    }
   ],
   "source": [
    "output_file = r'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Prep\\prep_trainings.csv'\n",
    "\n",
    "training_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Training data cleaned and saved to '{output_file}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for null values and datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   score_id     5000 non-null   int64 \n",
      " 1   Training_id  5000 non-null   int64 \n",
      " 2   Emp_id       5000 non-null   int64 \n",
      " 3   score        5000 non-null   int64 \n",
      " 4   punctuality  5000 non-null   int64 \n",
      " 5   discipline   5000 non-null   int64 \n",
      " 6   standards    5000 non-null   int64 \n",
      " 7   remarks      5000 non-null   object\n",
      " 8   is_promoted  5000 non-null   int64 \n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 351.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "scores_df = pd.read_csv(r'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Raw\\raw_scores.csv')\n",
    "\n",
    "scores_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "duplicates = scores_df.duplicated()\n",
    "count_Of_Duplicates = 0\n",
    "for i in duplicates:\n",
    "    if i == 'True':\n",
    "        count_Of_Duplicates += 1\n",
    "print(count_Of_Duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking if for a given course and employee duplicate records exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combination of E_id and T_id is unique.\n"
     ]
    }
   ],
   "source": [
    "scores_df['E_T_combined'] = scores_df['Emp_id'].astype(str) + '_' + scores_df['Training_id'].astype(str)\n",
    "\n",
    "duplicates = scores_df[scores_df.duplicated(subset='E_T_combined', keep=False)]\n",
    "\n",
    "if duplicates.empty:\n",
    "    print(\"The combination of E_id and T_id is unique.\")\n",
    "else:\n",
    "    print(\"The combination of E_id and T_id is not unique.\")\n",
    "    print(\"Duplicate entries:\")\n",
    "    print(duplicates)\n",
    "\n",
    "scores_df.drop(columns=['E_T_combined'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving csv file to Prep Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores data cleaned and saved to 'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Prep\\prep_scores.csv'.\n"
     ]
    }
   ],
   "source": [
    "output_file = r'C:\\Users\\VenkataRishitha\\Training\\Final Project 30-09-2024\\Data Engineering\\Prep\\prep_scores.csv'\n",
    "\n",
    "scores_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Scores data cleaned and saved to '{output_file}'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
